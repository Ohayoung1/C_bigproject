{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install yolo11m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    keypoints_data = []\n",
    "    if results[0].keypoints is not None and results[0].boxes.id is not None:\n",
    "        detections = results[0].keypoints\n",
    "        for kp in detections:\n",
    "            if kp is not None:\n",
    "                flat_keypoints = kp.xy.cpu().numpy().flatten().tolist()\n",
    "                keypoints_data.append(flat_keypoints)\n",
    "    return keypoints_data\n",
    "\n",
    "def resize_frame(frame, max_width=1280, max_height=720):\n",
    "    height, width = frame.shape[:2]\n",
    "    scale = min(max_width / width, max_height / height)\n",
    "    new_width, new_height = int(width * scale), int(height * scale)\n",
    "    return cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "action_labels = {0: \"Run\", 1: \"Sit\", 2: \"Walk\"}\n",
    "\n",
    "def process_video_or_webcam(yolo_model_path, lstm_model_path, seq_length, target_fps=3, video_path=None, camera_index=0):\n",
    "    yolo_model = YOLO(yolo_model_path)\n",
    "    lstm_model = load_model(lstm_model_path, compile=False)\n",
    "\n",
    "    object_sequences = {}\n",
    "    previous_actions = {}\n",
    "    previous_accuracies = {}\n",
    "\n",
    "    cap = cv2.VideoCapture(camera_index) if video_path is None else cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Unable to access {'webcam' if video_path is None else video_path}.\")\n",
    "        return\n",
    "\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    frame_interval = int(original_fps / target_fps)\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to read frame.\")\n",
    "            break\n",
    "\n",
    "        frame = resize_frame(frame, max_width=1280, max_height=720)\n",
    "\n",
    "        results = yolo_model.track(frame, persist=True, verbose=False)\n",
    "        keypoints_data = extract_keypoints(results)\n",
    "        ids = results[0].boxes.id.cpu().numpy() if results[0].boxes.id is not None else []\n",
    "\n",
    "        # 탐지된 객체 박스 및 행동 라벨 시각화\n",
    "        for box, obj_id in zip(results[0].boxes.xyxy, ids):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            color = (0, 255, 0)  # 기본 색상 (초록색)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "            action_label = action_labels.get(previous_actions.get(obj_id), \"Walk\")\n",
    "            accuracy = previous_accuracies.get(obj_id, 0.0)\n",
    "            label_text = f\"ID {obj_id}: {action_label} ({accuracy:.1f}%)\"\n",
    "            cv2.putText(frame, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "            # 키포인트 시각화\n",
    "            if keypoints_data:\n",
    "                for kp in keypoints_data:\n",
    "                    for i in range(0, len(kp), 2):  # x, y 좌표로 나누기\n",
    "                        cv2.circle(frame, (int(kp[i]), int(kp[i + 1])), 5, (255, 0, 0), -1)  # 관절 포인트 시각화\n",
    "\n",
    "        if frame_idx % frame_interval == 0:\n",
    "            for obj_id, keypoints in zip(ids, keypoints_data):\n",
    "                if obj_id not in object_sequences:\n",
    "                    object_sequences[obj_id] = deque(maxlen=seq_length)\n",
    "                    previous_actions[obj_id] = None\n",
    "                    previous_accuracies[obj_id] = 0.0\n",
    "                object_sequences[obj_id].append(keypoints)\n",
    "\n",
    "                if len(object_sequences[obj_id]) == seq_length:\n",
    "                    input_data = np.array(object_sequences[obj_id]).reshape(1, seq_length, -1)\n",
    "                    prediction = lstm_model.predict(input_data, verbose=0)\n",
    "                    action_class = np.argmax(prediction)\n",
    "                    accuracy = float(np.max(prediction)) * 100\n",
    "\n",
    "                    class_probabilities = {action_labels[i]: round(prob * 100, 2) for i, prob in enumerate(prediction[0])}\n",
    "                    print(f\"ID {obj_id} Predictions: {class_probabilities}\")\n",
    "\n",
    "                    previous_actions[obj_id] = action_class\n",
    "                    previous_accuracies[obj_id] = accuracy\n",
    "\n",
    "        cv2.imshow(\"YOLO Pose + LSTM Action Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Processing stopped.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    yolo_model_path = \"./Model/yolo11m-pose.pt\"  # YOLO 모델 경로\n",
    "    lstm_model_path = \"./Model/LSTM.h5\"          # LSTM 모델 경로\n",
    "    seq_length = 3                                # LSTM 입력 시퀀스 길이\n",
    "    target_fps = 3                                # 목표 FPS\n",
    "    video_path = None                              # 비디오 경로 (None이면 웹캠 사용)\n",
    "    camera_index = 0                              # 웹캠 인덱스\n",
    "\n",
    "    process_video_or_webcam(yolo_model_path, lstm_model_path, seq_length, target_fps, video_path, camera_index)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
